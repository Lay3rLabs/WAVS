use std::str::FromStr as _;

use crate::service_json::Json;

use super::*;
use alloy_primitives::address;
use alloy_primitives::hex;
use layer_climb::prelude::{ChainConfig, ChainId};
use layer_climb::querier::QueryClient as CosmosQueryClient;
use tempfile::tempdir;
use utils::init_tracing_tests;

#[test]
fn test_service_init() {
    // Create a temporary directory for the test
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("test_service.json");

    // Initialize service
    let result = init_service(&file_path, "Test Service".to_string()).unwrap();

    // Verify the result
    assert_eq!(result.service.name, "Test Service");
    assert_eq!(result.file_path, file_path);

    // Verify the file was created
    assert!(file_path.exists());

    // Parse the created file to verify its contents
    let file_content = std::fs::read_to_string(file_path).unwrap();
    let parsed_service: ServiceJson = serde_json::from_str(&file_content).unwrap();

    assert_eq!(parsed_service.name, "Test Service");

    // Test with autogenerated ID
    let auto_id_file_path = temp_dir.path().join("auto_id_test.json");

    // Initialize service with no ID (should generate one)
    let auto_id_result = init_service(&auto_id_file_path, "Auto ID Service".to_string()).unwrap();

    // Verify name
    assert_eq!(auto_id_result.service.name, "Auto ID Service");

    // Verify file was created
    assert!(auto_id_file_path.exists());

    // Parse file to verify contents
    let auto_id_content = std::fs::read_to_string(auto_id_file_path).unwrap();
    let auto_id_parsed: ServiceJson = serde_json::from_str(&auto_id_content).unwrap();

    assert_eq!(auto_id_parsed.name, "Auto ID Service");
}

#[test]
fn test_workflow_component_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("component_operations_test.json");

    // Create a test digest - raw 64-character hex string (32 bytes)
    let test_digest = ComponentDigest::from_str(
        "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
    )
    .unwrap();

    // Initialize a service using the init_service method
    let init_result = init_service(&file_path, "Test Service".to_string()).unwrap();

    // Verify initialization result
    assert_eq!(init_result.service.name, "Test Service");
    assert_eq!(init_result.file_path, file_path);

    // Need to have a valid workflow before we can work on its component
    let workflow_id = WorkflowID::new("workflow-1").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Test adding first component using Digest source
    let add_result =
        set_component_source_digest(&file_path, workflow_id.clone(), test_digest.clone()).unwrap();

    // Verify add result
    assert_eq!(add_result.digest, test_digest);
    assert_eq!(add_result.file_path, file_path);

    // Verify the file was modified by adding the component
    let service_after_add: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_add
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .is_set());

    // Test adding second component with Digest source
    let workflow_id_2 = WorkflowID::new("workflow-2").unwrap();
    add_workflow(&file_path, Some(workflow_id_2.clone())).unwrap();

    let second_add_result =
        set_component_source_digest(&file_path, workflow_id_2.clone(), test_digest.clone())
            .unwrap();

    // Verify second add result
    assert_eq!(second_add_result.digest, test_digest);

    // Test updating permissions - allow all HTTP hosts
    let permissions_result = update_component_permissions(
        &file_path,
        workflow_id.clone(),
        Some(vec!["*".to_string()]),
        Some(true),
    )
    .unwrap();

    // Verify permissions result
    assert!(permissions_result.permissions.file_system);
    assert!(matches!(
        permissions_result.permissions.allowed_http_hosts,
        AllowedHostPermission::All
    ));

    // Verify the service was updated with new permissions
    let service_after_permissions: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let updated_component = service_after_permissions
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert!(updated_component.permissions.file_system);
    assert!(matches!(
        updated_component.permissions.allowed_http_hosts,
        AllowedHostPermission::All
    ));

    // Test updating to specific HTTP hosts
    let specific_hosts = vec!["example.com".to_string(), "api.example.com".to_string()];
    let specific_hosts_result = update_component_permissions(
        &file_path,
        workflow_id_2.clone(),
        Some(specific_hosts.clone()),
        None,
    )
    .unwrap();

    // Verify specific hosts result
    if let AllowedHostPermission::Only(hosts) =
        &specific_hosts_result.permissions.allowed_http_hosts
    {
        assert_eq!(hosts.len(), 2);
        assert!(hosts.contains(&"example.com".to_string()));
        assert!(hosts.contains(&"api.example.com".to_string()));
    } else {
        panic!("Expected AllowedHostPermission::Only");
    }

    // Verify the service was updated with specific hosts
    let service_after_specific: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let specific_component = service_after_specific
        .workflows
        .get(&workflow_id_2)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    if let AllowedHostPermission::Only(hosts) = &specific_component.permissions.allowed_http_hosts {
        assert_eq!(hosts.len(), 2);
        assert!(hosts.contains(&"example.com".to_string()));
        assert!(hosts.contains(&"api.example.com".to_string()));
    } else {
        panic!("Expected AllowedHostPermission::Only");
    }

    // Test updating to no HTTP hosts
    let no_hosts_result =
        update_component_permissions(&file_path, workflow_id.clone(), Some(vec![]), None).unwrap();

    // Verify no hosts result
    assert!(matches!(
        no_hosts_result.permissions.allowed_http_hosts,
        AllowedHostPermission::None
    ));

    // Verify the service was updated with no hosts permission
    let service_after_no_hosts: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let no_hosts_component = service_after_no_hosts
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    assert!(matches!(
        no_hosts_component.permissions.allowed_http_hosts,
        AllowedHostPermission::None
    ));

    // Test error handling for permissions update with non-existent component
    let non_existent_id = WorkflowID::new("does-not-exist").unwrap();
    let error_permissions = update_component_permissions(
        &file_path,
        non_existent_id.clone(),
        Some(vec!["*".to_string()]),
        None,
    );

    // Verify error for permissions update
    assert!(error_permissions.is_err());
    let permissions_error = error_permissions.unwrap_err().to_string();
    assert!(permissions_error.contains(&non_existent_id.to_string()));
    assert!(permissions_error.contains("not found"));

    // Test adding third component with Digest source
    // Need to have a valid workflow before we can work on its component
    let workflow_id_3 = WorkflowID::new("workflow-3").unwrap();
    add_workflow(&file_path, Some(workflow_id_3.clone())).unwrap();

    let third_add_result =
        set_component_source_digest(&file_path, workflow_id_3.clone(), test_digest.clone())
            .unwrap();

    // Verify third add result
    assert_eq!(third_add_result.digest, test_digest);

    // Verify the third component was added
    let service_after_third_add: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_third_add
        .workflows
        .get(&workflow_id_3)
        .unwrap()
        .component
        .is_set());

    // Test setting a specific fuel limit
    let fuel_limit = 50000u64;
    let fuel_limit_result =
        update_component_fuel_limit(&file_path, workflow_id.clone(), Some(fuel_limit)).unwrap();

    // Verify fuel limit result
    assert_eq!(fuel_limit_result.fuel_limit, Some(fuel_limit));
    assert_eq!(fuel_limit_result.file_path, file_path);

    // Verify the service was updated with the fuel limit
    let service_after_fuel_limit: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_fuel_limit = service_after_fuel_limit
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_fuel_limit.fuel_limit, Some(fuel_limit));

    // Test removing a fuel limit (setting to None)
    let no_fuel_limit_result =
        update_component_fuel_limit(&file_path, workflow_id.clone(), None).unwrap();

    // Verify no fuel limit result
    assert_eq!(no_fuel_limit_result.fuel_limit, None);
    assert_eq!(no_fuel_limit_result.file_path, file_path);

    // Verify the service was updated with no fuel limit
    let service_after_no_fuel: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_no_fuel = service_after_no_fuel
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_no_fuel.fuel_limit, None);

    // Test adding configuration values
    let config_values = vec![
        "api_key=123456".to_string(),
        "timeout=30".to_string(),
        "debug=true".to_string(),
    ];
    let config_result =
        update_component_config(&file_path, workflow_id.clone(), Some(config_values.clone()))
            .unwrap();

    // Verify config result
    assert_eq!(config_result.config.len(), 3);
    assert!(config_result
        .config
        .iter()
        .any(|(k, v)| k == "api_key" && v == "123456"));
    assert!(config_result
        .config
        .iter()
        .any(|(k, v)| k == "timeout" && v == "30"));
    assert!(config_result
        .config
        .iter()
        .any(|(k, v)| k == "debug" && v == "true"));
    assert_eq!(config_result.file_path, file_path);

    // Verify the service was updated with the config
    let service_after_config: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_config = service_after_config
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_config.config.len(), 3);
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "api_key" && v == "123456"));
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "timeout" && v == "30"));
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "debug" && v == "true"));

    // Test clearing configuration (set to None)
    let clear_config_result =
        update_component_config(&file_path, workflow_id.clone(), None).unwrap();

    // Verify clear config result
    assert_eq!(clear_config_result.config.len(), 0);
    assert_eq!(clear_config_result.file_path, file_path);

    // Verify the service was updated with empty config
    let service_after_clear_config: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_clear_config = service_after_clear_config
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_clear_config.config.len(), 0);

    // Test with invalid config format
    let invalid_config = vec!["invalid_format".to_string()];
    let invalid_config_result =
        update_component_config(&file_path, workflow_id.clone(), Some(invalid_config));

    // Verify it returns an error for invalid format
    assert!(invalid_config_result.is_err());
    let error_msg = invalid_config_result.unwrap_err().to_string();
    assert!(error_msg.contains("Invalid config format"));
    assert!(error_msg.contains("Expected 'key=value'"));

    // Test adding environment variables
    let env_keys = vec![
        "WAVS_ENV_API_KEY".to_string(),
        "WAVS_ENV_SECRET_TOKEN".to_string(),
        "WAVS_ENV_DATABASE_URL".to_string(),
    ];

    let env_result =
        update_component_env_keys(&file_path, workflow_id.clone(), Some(env_keys.clone())).unwrap();

    // Verify env result
    assert_eq!(env_result.env_keys.len(), 3);
    assert!(env_result.env_keys.contains("WAVS_ENV_API_KEY"));
    assert!(env_result.env_keys.contains("WAVS_ENV_SECRET_TOKEN"));
    assert!(env_result.env_keys.contains("WAVS_ENV_DATABASE_URL"));

    // Verify the service was updated with env keys
    let service_after_env: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_env = service_after_env
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    assert_eq!(component_with_env.env_keys.len(), 3);
    assert!(component_with_env.env_keys.contains("WAVS_ENV_API_KEY"));
    assert!(component_with_env
        .env_keys
        .contains("WAVS_ENV_SECRET_TOKEN"));
    assert!(component_with_env
        .env_keys
        .contains("WAVS_ENV_DATABASE_URL"));

    // Test validation of env keys
    let invalid_env_keys = vec!["WAVS_ENV_VALID".to_string(), "INVALID_PREFIX".to_string()];

    let invalid_result =
        update_component_env_keys(&file_path, workflow_id.clone(), Some(invalid_env_keys));

    // Verify it returns an error for invalid prefix
    assert!(invalid_result.is_err());
    let error_msg = invalid_result.unwrap_err().to_string();
    assert!(error_msg.contains("must start with 'WAVS_ENV'"));

    // Test clearing env keys
    let clear_env_result =
        update_component_env_keys(&file_path, workflow_id.clone(), None).unwrap();

    // Verify clear result
    assert_eq!(clear_env_result.env_keys.len(), 0);

    // Test setting a specific max execution time
    let max_exec_time = 120u64;
    let max_exec_result =
        update_component_time_limit_seconds(&file_path, workflow_id_2.clone(), Some(max_exec_time))
            .unwrap();

    // Verify max exec time result
    assert_eq!(max_exec_result.time_limit_seconds, Some(max_exec_time));
    assert_eq!(max_exec_result.file_path, file_path);

    // Verify the service was updated with max exec time
    let service_after_max_exec: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_max_exec = service_after_max_exec
        .workflows
        .get(&workflow_id_2)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(
        component_with_max_exec.time_limit_seconds,
        Some(max_exec_time)
    );

    // Test removing max exec time (setting to None)
    let no_max_exec_result =
        update_component_time_limit_seconds(&file_path, workflow_id_2.clone(), None).unwrap();

    // Verify no max exec time result
    assert_eq!(no_max_exec_result.time_limit_seconds, None);
    assert_eq!(no_max_exec_result.file_path, file_path);

    // Verify the service was updated with no max exec time
    let service_after_no_max_exec: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_no_max_exec = service_after_no_max_exec
        .workflows
        .get(&workflow_id_2)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_no_max_exec.time_limit_seconds, None);
}

#[test]
fn test_workflow_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("workflow_operations_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Test adding a workflow with specific ID
    let workflow_id = WorkflowID::new("workflow-123").unwrap();
    let add_result = add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Verify add result
    assert_eq!(add_result.workflow_id, workflow_id);
    assert_eq!(add_result.file_path, file_path);

    // Verify the file was modified by adding the workflow
    let service_after_add: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_add.workflows.contains_key(&workflow_id));
    assert_eq!(service_after_add.workflows.len(), 1);

    // Verify workflow properties - need to handle TriggerJson and SubmitJson wrappers
    let added_workflow = service_after_add.workflows.get(&workflow_id).unwrap();

    // Check trigger type with pattern matching for TriggerJson
    if let TriggerJson::Json(json) = &added_workflow.trigger {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Check component type
    assert!(added_workflow.component.is_unset());

    // Check submit type with pattern matching for SubmitJson
    if let SubmitJson::Json(json) = &added_workflow.submit {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Test adding a workflow with autogenerated ID
    let auto_id_result = add_workflow(&file_path, None).unwrap();
    let auto_workflow_id = auto_id_result.workflow_id;

    // Verify the auto-generated workflow was added
    let service_after_auto: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_auto.workflows.contains_key(&auto_workflow_id));
    assert_eq!(service_after_auto.workflows.len(), 2); // Two workflows now

    // Test deleting a workflow
    let delete_result = delete_workflow(&file_path, workflow_id.clone()).unwrap();

    // Verify delete result
    assert_eq!(delete_result.workflow_id, workflow_id);
    assert_eq!(delete_result.file_path, file_path);

    // Verify the file was modified by deleting the workflow
    let service_after_delete: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(!service_after_delete.workflows.contains_key(&workflow_id));
    assert_eq!(service_after_delete.workflows.len(), 1); // One workflow remaining

    // Test error handling for non-existent workflow
    let non_existent_workflow = WorkflowID::new("does-not-exist").unwrap();
    let workflow_error = delete_workflow(&file_path, non_existent_workflow.clone());

    // Verify it returns an error with appropriate message
    assert!(workflow_error.is_err());
    let workflow_error_msg = workflow_error.unwrap_err().to_string();
    assert!(workflow_error_msg.contains(&non_existent_workflow.to_string()));
    assert!(workflow_error_msg.contains("not found"));
}

#[tokio::test]
async fn test_update_status() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("update_status.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Update the status to Paused
    let result = update_status(&file_path, ServiceStatus::Paused).unwrap();

    // Assert the result reflects the new status and correct file path
    assert_eq!(result.status, ServiceStatus::Paused);
    assert_eq!(result.file_path, file_path);

    // Re-read the service file and assert the status was updated
    let contents = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&contents).unwrap();
    assert_eq!(service.status, ServiceStatus::Paused);
}

#[tokio::test]
async fn test_workflow_trigger_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("workflow_trigger_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Add a workflow
    let workflow_id = WorkflowID::new("workflow-123").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Initial workflow should have manual trigger (default when created)
    let service_initial: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let initial_workflow = service_initial.workflows.get(&workflow_id).unwrap();

    // Check the trigger type with proper handling of TriggerJson wrapper
    if let TriggerJson::Json(json) = &initial_workflow.trigger {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Create a mock CosmosQueryClient for testing
    let cosmos_chain_name = ChainName::from_str("cosmoshub-4").unwrap();
    let chain_config = ChainConfig {
        chain_id: ChainId::new(cosmos_chain_name.clone()),
        rpc_endpoint: Some("https://rpc.cosmos.network".to_string()),
        grpc_endpoint: Some("https://grpc.cosmos.network:443".to_string()),
        grpc_web_endpoint: Some("https://grpc-web.cosmos.network".to_string()),
        gas_price: 0.025,
        gas_denom: "uatom".to_string(),
        address_kind: layer_climb::prelude::AddrKind::Cosmos {
            prefix: "cosmos".to_string(),
        },
    };
    let query_client = CosmosQueryClient::new(chain_config, None)
        .await
        .expect("Failed to create Cosmos query client");

    // Test setting Cosmos trigger
    let cosmos_address = "cosmos1fl48vsnmsdzcv85q5d2q4z5ajdha8yu34mf0eh".to_string();
    let cosmos_event = "transfer".to_string();

    let cosmos_result = set_cosmos_trigger(
        query_client.clone(),
        &file_path,
        workflow_id.clone(),
        cosmos_address.clone(),
        cosmos_chain_name.clone(),
        cosmos_event.clone(),
    )
    .unwrap();

    // Verify cosmos trigger result
    assert_eq!(cosmos_result.workflow_id, workflow_id);
    if let Trigger::CosmosContractEvent {
        address,
        chain_name,
        event_type,
    } = &cosmos_result.trigger
    {
        assert_eq!(address.to_string(), cosmos_address);
        assert_eq!(chain_name, &cosmos_chain_name);
        assert_eq!(event_type, &cosmos_event);
    } else {
        panic!("Expected CosmosContractEvent trigger");
    }

    // Verify the service was updated with cosmos trigger
    let service_after_cosmos: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let cosmos_workflow = service_after_cosmos.workflows.get(&workflow_id).unwrap();

    // Handle TriggerJson wrapper
    if let TriggerJson::Trigger(trigger) = &cosmos_workflow.trigger {
        if let Trigger::CosmosContractEvent {
            address,
            chain_name,
            event_type,
        } = trigger
        {
            assert_eq!(address.to_string(), cosmos_address);
            assert_eq!(chain_name, &cosmos_chain_name);
            assert_eq!(event_type, &cosmos_event);
        } else {
            panic!("Expected CosmosContractEvent trigger in service");
        }
    } else {
        panic!("Expected TriggerJson::Trigger");
    }

    // Test for incorrect prefix - using Neutron (ntrn) prefix on Cosmos Hub
    let neutron_address = "ntrn1m8wnvy0jk8xf0hhn5uycrhjr3zpaqf4d0z9k8f".to_string();
    let wrong_prefix_result = set_cosmos_trigger(
        query_client.clone(),
        &file_path,
        workflow_id.clone(),
        neutron_address,
        cosmos_chain_name.clone(),
        cosmos_event.clone(),
    );

    // This should fail with a prefix validation error
    assert!(wrong_prefix_result.is_err());
    assert!(wrong_prefix_result
        .unwrap_err()
        .to_string()
        .contains("invalid bech32"),);

    // Test setting EVM trigger
    let evm_address = address!("0x00000000219ab540356cBB839Cbe05303d7705Fa");
    let evm_chain = ChainName::from_str("ethereum-mainnet").unwrap();
    let evm_event_hash =
        "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef".to_string();

    let evm_result = set_evm_trigger(
        &file_path,
        workflow_id.clone(),
        evm_address,
        evm_chain.clone(),
        evm_event_hash.clone(),
    )
    .unwrap();

    // Verify EVM trigger result
    assert_eq!(evm_result.workflow_id, workflow_id);
    if let Trigger::EvmContractEvent {
        address,
        chain_name,
        event_hash,
    } = &evm_result.trigger
    {
        assert_eq!(*address, evm_address);
        assert_eq!(chain_name, &evm_chain);
        // For event_hash we'll need to check the bytes match what we expect
        let expected_hash_bytes = hex::decode(evm_event_hash.trim_start_matches("0x")).unwrap();
        assert_eq!(event_hash.as_slice(), &expected_hash_bytes[..]);
    } else {
        panic!("Expected EvmContractEvent trigger");
    }

    // Verify the service was updated with EVM trigger
    let service_after: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let evm_workflow = service_after.workflows.get(&workflow_id).unwrap();

    // Handle TriggerJson wrapper
    if let TriggerJson::Trigger(trigger) = &evm_workflow.trigger {
        if let Trigger::EvmContractEvent {
            address,
            chain_name,
            event_hash,
        } = trigger
        {
            assert_eq!(*address, evm_address);
            assert_eq!(chain_name, &evm_chain);
            let expected_hash_bytes = hex::decode(evm_event_hash.trim_start_matches("0x")).unwrap();
            assert_eq!(event_hash.as_slice(), &expected_hash_bytes[..]);
        } else {
            panic!("Expected EvmContractEvent trigger in service");
        }
    } else {
        panic!("Expected TriggerJson::Trigger");
    }

    // Test error handling for non-existent workflow
    let non_existent_workflow = WorkflowID::new("does-not-exist").unwrap();
    let trigger_error = set_evm_trigger(
        &file_path,
        non_existent_workflow.clone(),
        evm_address,
        evm_chain.clone(),
        evm_event_hash.clone(),
    );

    // Verify it returns an error with appropriate message
    assert!(trigger_error.is_err());
    let trigger_error_msg = trigger_error.unwrap_err().to_string();
    assert!(trigger_error_msg.contains(&non_existent_workflow.to_string()));
    assert!(trigger_error_msg.contains("not found"));

    // Test error handling for invalid addresses
    let invalid_cosmos_address = "invalid-cosmos-address".to_string();
    let invalid_cosmos_result = set_cosmos_trigger(
        query_client, // Reuse the same query client
        &file_path,
        workflow_id.clone(),
        invalid_cosmos_address,
        cosmos_chain_name.clone(),
        cosmos_event.clone(),
    );
    assert!(invalid_cosmos_result.is_err());
    assert!(invalid_cosmos_result
        .unwrap_err()
        .to_string()
        .contains("invalid bech32"));

    // Test setting BlockInterval trigger
    let interval_chain = ChainName::from_str("polygon-mainnet").unwrap();
    let n_blocks = NonZeroU32::new(10).unwrap();

    let block_interval_result = set_block_interval_trigger(
        &file_path,
        workflow_id.clone(),
        interval_chain.clone(),
        n_blocks,
        Some(NonZeroU64::new(42).unwrap()),
        None,
    )
    .unwrap();

    assert_eq!(block_interval_result.workflow_id, workflow_id);
    if let Trigger::BlockInterval {
        chain_name,
        n_blocks: blocks,
        start_block,
        end_block,
    } = &block_interval_result.trigger
    {
        assert_eq!(chain_name, &interval_chain);
        assert_eq!(*blocks, n_blocks);
        assert_eq!(*start_block, Some(NonZeroU64::new(42).unwrap()));
        assert_eq!(*end_block, None);
    } else {
        panic!("Expected BlockInterval trigger");
    }

    // Test setting Cron trigger
    let cron_expr = "0 0 * * * *".to_string(); // every hour
    let start_time = Some(Timestamp::from_nanos(1_000_000_000_000_000_000));
    let end_time = Some(Timestamp::from_nanos(2_000_000_000_000_000_000));

    let cron_result = set_cron_trigger(
        &file_path,
        workflow_id.clone(),
        cron::Schedule::from_str(&cron_expr).unwrap(),
        start_time,
        end_time,
    )
    .unwrap();

    assert_eq!(cron_result.workflow_id, workflow_id);
    if let Trigger::Cron {
        schedule,
        start_time: s,
        end_time: e,
    } = &cron_result.trigger
    {
        assert_eq!(schedule, &cron_expr);
        assert_eq!(s, &start_time);
        assert_eq!(e, &end_time);
    } else {
        panic!("Expected Cron trigger");
    }
}

#[test]
fn test_workflow_submit_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("workflow_submit_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Add a workflow
    let workflow_id = WorkflowID::new("workflow-123").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Initial workflow should have None submit (default when created)
    let service_initial: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let initial_workflow = service_initial.workflows.get(&workflow_id).unwrap();

    // Handle SubmitJson wrapper
    if let SubmitJson::Json(json) = &initial_workflow.submit {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Test setting Aggregator submit
    let aggregator_url = "https://api.example.com/aggregator".to_string();
    let evm_address = address!("0x00000000219ab540356cBB839Cbe05303d7705Fa");
    let evm_chain = ChainName::from_str("ethereum-mainnet").unwrap();
    let max_gas = Some(1000000u64);

    let aggregator_result = set_aggregator_submit(
        &file_path,
        workflow_id.clone(),
        aggregator_url.clone(),
        evm_chain.clone(),
        evm_address,
        max_gas,
    )
    .unwrap();

    // Verify aggregator submit result
    assert_eq!(aggregator_result.workflow_id, workflow_id);
    if let Submit::Aggregator { url, .. } = &aggregator_result.submit {
        assert_eq!(url, &aggregator_url);
    } else {
        panic!("Expected Aggregator submit");
    }

    // Verify the service was updated with aggregator submit
    let service_after_aggregator: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let aggregator_workflow = service_after_aggregator
        .workflows
        .get(&workflow_id)
        .unwrap();

    // Handle SubmitJson wrapper
    let aggregators = match &aggregator_workflow.submit {
        SubmitJson::Submit(Submit::Aggregator {
            url,
            evm_contracts: Some(contracts),
            ..
        }) => {
            assert_eq!(url, &aggregator_url);
            contracts
        }
        _ => panic!("Expected Aggregator submit with evm_contracts"),
    };

    let evm = &aggregators[0];
    assert_eq!(evm.chain_name, evm_chain);
    assert_eq!(evm.address, evm_address);
    assert_eq!(evm.max_gas, max_gas);

    // Test updating with null max_gas
    let _ = set_aggregator_submit(
        &file_path,
        workflow_id.clone(),
        aggregator_url.clone(),
        evm_chain.clone(),
        evm_address,
        None,
    )
    .unwrap();

    let service_after_aggregator: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let aggregator_workflow = service_after_aggregator
        .workflows
        .get(&workflow_id)
        .unwrap();
    let aggregator = match &aggregator_workflow.submit {
        SubmitJson::Submit(Submit::Aggregator {
            evm_contracts: Some(contracts),
            ..
        }) => contracts,
        _ => panic!("Expected Aggregator submit with evm_contracts"),
    };

    let evm = &aggregator[0];
    assert_eq!(evm.chain_name, evm_chain);
    assert_eq!(evm.address, evm_address);
    assert_eq!(evm.max_gas, None);

    // Test error handling for invalid URL
    let invalid_url = "not-a-valid-url".to_string();
    let invalid_url_result = set_aggregator_submit(
        &file_path,
        workflow_id.clone(),
        invalid_url,
        evm_chain.clone(),
        evm_address,
        None,
    );
    assert!(invalid_url_result.is_err());
    let invalid_url_error = invalid_url_result.unwrap_err().to_string();
    assert!(invalid_url_error.contains("Invalid URL format"));

    // Test add_aggregator_submit function
    let second_address = address!("0x1111111111111111111111111111111111111111");
    let second_chain = ChainName::from_str("base").unwrap();
    let second_max_gas = Some(2000000u64);

    let add_result = add_aggregator_submit(
        &file_path,
        workflow_id.clone(),
        aggregator_url.clone(),
        second_chain.clone(),
        second_address,
        second_max_gas,
    )
    .unwrap();

    // Verify add_aggregator_submit result
    assert_eq!(add_result.workflow_id, workflow_id);
    assert_eq!(add_result.aggregator_submits.len(), 2);

    // Verify the service now has two aggregators
    let service_with_two_aggregators: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let workflow_with_two = service_with_two_aggregators
        .workflows
        .get(&workflow_id)
        .unwrap();
    let two_aggregators = match &workflow_with_two.submit {
        SubmitJson::Submit(Submit::Aggregator {
            evm_contracts: Some(contracts),
            ..
        }) => contracts,
        _ => panic!("Expected Aggregator submit with evm_contracts"),
    };

    assert_eq!(two_aggregators.len(), 2);

    // Check second aggregator was added
    let second_evm = &two_aggregators[1];
    assert_eq!(second_evm.chain_name, second_chain);
    assert_eq!(second_evm.address, second_address);
    assert_eq!(second_evm.max_gas, second_max_gas);

    // Test error handling for add_aggregator_submit with non-existent workflow
    let non_existent_workflow = WorkflowID::new("non-existent").unwrap();
    let non_existent_result = add_aggregator_submit(
        &file_path,
        non_existent_workflow,
        aggregator_url.clone(),
        evm_chain,
        evm_address,
        None,
    );
    assert!(non_existent_result.is_err());
    let non_existent_error = non_existent_result.unwrap_err().to_string();
    assert!(non_existent_error.contains("Workflow with ID 'non-existent' not found"));
}

#[tokio::test]
async fn test_service_validation() {
    // Create a temporary directory for test files
    let temp_dir = tempdir().unwrap();

    // Create common test objects
    let workflow_id = WorkflowID::new("workflow-123").unwrap();
    let evm_chain = ChainName::from_str("ethereum-mainnet").unwrap();
    let evm_address = alloy_primitives::Address::parse_checksummed(
        "0x00000000219ab540356cBB839Cbe05303d7705Fa",
        None,
    )
    .unwrap();

    // Create component with digest
    let test_digest = ComponentDigest::from_str(
        "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
    )
    .unwrap();
    let component = Component::new(ComponentSource::Digest(test_digest.clone()));

    // Create a valid trigger and submit for the workflow
    let trigger = Trigger::EvmContractEvent {
        address: evm_address,
        chain_name: evm_chain.clone(),
        event_hash: wavs_types::ByteArray::new([1u8; 32]),
    };

    let aggregator = EvmContractSubmission {
        address: evm_address,
        chain_name: evm_chain.clone(),
        max_gas: Some(1000000u64),
    };

    let submit = Submit::Aggregator {
        url: "https://api.example.com/aggregator".to_string(),
        component: None,
        evm_contracts: Some(vec![aggregator]),
        cosmos_contracts: None,
    };

    // Create service manager
    let manager = ServiceManagerJson::Manager(ServiceManager::Evm {
        chain_name: evm_chain.clone(),
        address: evm_address,
    });

    // Test valid service
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let valid_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("valid_service.json");
        let service_json = serde_json::to_string_pretty(&valid_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert_eq!(
            result.errors.len(),
            0,
            "Valid service should have no validation errors"
        );
    }

    // Test unset component
    {
        let mut workflows = BTreeMap::new();
        // Add original workflow
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        // Add invalid workflow with unset component
        let invalid_workflow_id = WorkflowID::new("invalid-workflow").unwrap();
        workflows.insert(
            invalid_workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::new_unset(),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let invalid_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("unset_component.json");
        let service_json = serde_json::to_string_pretty(&invalid_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Service with unset component should have errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains(&invalid_workflow_id.to_string())
                    && error.contains("has an unset component")),
            "Validation should catch missing component reference"
        );
    }

    // Test zero fuel limit
    {
        let mut workflows = BTreeMap::new();
        let mut zero_fuel_component = component.clone();
        zero_fuel_component.fuel_limit = Some(0);

        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(zero_fuel_component),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let zero_fuel_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("zero_fuel_service.json");
        let service_json = serde_json::to_string_pretty(&zero_fuel_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Zero fuel service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains(&workflow_id.to_string())
                    && error.contains("fuel limit of zero")),
            "Validation should catch zero fuel limit"
        );
    }

    // Test empty service name
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let empty_name_service = ServiceJson {
            name: "".to_string(), // Empty name
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("empty_name_service.json");
        let service_json = serde_json::to_string_pretty(&empty_name_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Empty name service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("Service name cannot be empty")),
            "Validation should catch empty service name"
        );
    }

    // Test invalid environment variable prefix
    {
        let mut workflows = BTreeMap::new();
        let mut env_component = component.clone();
        env_component.env_keys = ["INVALID_PREFIX_KEY".to_string()].into_iter().collect();

        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(env_component),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let invalid_env_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("invalid_env_prefix.json");
        let service_json = serde_json::to_string_pretty(&invalid_env_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Invalid env prefix service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("doesn't start with 'WAVS_ENV'")),
            "Validation should catch invalid environment variable prefix"
        );
    }

    // Test unset trigger
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Json(Json::Unset),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let unset_trigger_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("unset_trigger.json");
        let service_json = serde_json::to_string_pretty(&unset_trigger_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Unset trigger service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("has an unset trigger")),
            "Validation should catch unset trigger"
        );
    }

    // Test zero max_gas in aggregator
    {
        let mut workflows = BTreeMap::new();

        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(Submit::Aggregator {
                    url: "https://api.example.com/aggregator".to_string(),
                    component: None,
                    evm_contracts: Some(vec![EvmContractSubmission {
                        address: evm_address,
                        chain_name: evm_chain.clone(),
                        max_gas: Some(0u64), // Zero gas
                    }]),
                    cosmos_contracts: None,
                }),
            },
        );

        let zero_gas_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("zero_max_gas.json");
        let service_json = serde_json::to_string_pretty(&zero_gas_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Zero max_gas service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("max_gas of zero")),
            "Validation should catch zero max_gas"
        );
    }

    // Test unset submit
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Json(Json::Unset),
            },
        );

        let unset_submit_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("unset_submit.json");
        let service_json = serde_json::to_string_pretty(&unset_submit_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Unset submit service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("has an unset submit")),
            "Validation should catch unset submit"
        );
    }

    // Test invalid URL in Aggregator submit
    {
        let mut workflows = BTreeMap::new();
        let aggregators = vec![EvmContractSubmission {
            address: evm_address,
            chain_name: evm_chain.clone(),
            max_gas: Some(1000000u64),
        }];

        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(Submit::Aggregator {
                    url: "not-a-valid-url".to_string(),
                    component: None,
                    evm_contracts: Some(aggregators),
                    cosmos_contracts: None,
                }),
            },
        );

        let invalid_url_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("invalid_url.json");
        let service_json = serde_json::to_string_pretty(&invalid_url_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Invalid URL service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("invalid URL")),
            "Validation should catch invalid URL in Aggregator submit"
        );
    }

    // Test unset service manager
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let unset_manager_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: ServiceManagerJson::Json(Json::Unset),
        };

        let file_path = temp_dir.path().join("unset_manager.json");
        let service_json = serde_json::to_string_pretty(&unset_manager_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Unset manager service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("unset service manager")),
            "Validation should catch unset service manager"
        );
    }

    // Test submit with aggregator but no aggregator defined
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(Submit::Aggregator {
                    url: "https://example.com".to_string(),
                    component: None,
                    evm_contracts: None,
                    cosmos_contracts: None,
                }),
            },
        );

        let no_aggregator_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("no_aggregator.json");
        let service_json = serde_json::to_string_pretty(&no_aggregator_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "No aggregator service should have validation errors"
        );
        assert!(
            result.errors.iter().any(|error| error
                .contains("submits with aggregator, but no aggregator contracts are defined")),
            "Validation should catch submit with aggregator but no aggregator defined"
        );
    }
}

#[tokio::test]
async fn test_set_component_source_registry() {
    init_tracing_tests();
    // Create a temporary directory for the test
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("component_registry_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Add a workflow
    let workflow_id = WorkflowID::new("workflow-123").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Test setting a component source to a registry
    let package = PackageRef::try_from("wavs-tests:square".to_string()).unwrap();

    // Use wa.dev as the registry domain (WAVS default)
    let registry_domain = "wa.dev".to_string();

    // Call the function to set the component source
    let result = set_component_source_registry(
        &file_path,
        workflow_id.clone(),
        None, // Use default domain
        package.clone(),
        None, // Use latest version
    )
    .await;

    // Verify the operation was successful
    assert!(
        result.is_ok(),
        "Failed to set component source: {:?}",
        result.err()
    );

    let result = result.unwrap();

    // Basic validation of the result
    assert_eq!(result.package, package);
    assert_eq!(result.domain, registry_domain);
    assert!(
        !result.digest.to_string().is_empty(),
        "Digest should not be empty"
    );

    // Verify the service was updated with the registry source
    let service_json = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&service_json).unwrap();

    let workflow = service.workflows.get(&workflow_id).unwrap();

    if let ComponentJson::Component(component) = &workflow.component {
        if let ComponentSource::Registry { registry } = &component.source {
            assert_eq!(registry.package, package);
            assert!(
                !registry.digest.to_string().is_empty(),
                "Digest in registry should not be empty"
            );
            assert_eq!(
                registry.digest, result.digest,
                "Digest in service file should match result digest"
            );
            // We used defaults here
            assert!(registry.version.is_none());
            assert!(registry.domain.is_none());
        } else {
            panic!("Expected Registry component source");
        }
    } else {
        panic!("Expected Component");
    }
}
