use std::str::FromStr as _;

use crate::service_json::Json;

use super::*;
use alloy_primitives::address;
use alloy_primitives::hex;
use layer_climb::prelude::ChainConfig;
use layer_climb::querier::QueryClient as CosmosQueryClient;
use tempfile::tempdir;
use utils::init_tracing_tests;
use utils::service::DEFAULT_IPFS_GATEWAY;
use wasm_pkg_client::PackageRef;
use wavs_types::ComponentDigest;
use wavs_types::SignatureKind;
use wavs_types::Submit;

#[test]
fn test_service_init() {
    // Create a temporary directory for the test
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("test_service.json");

    // Initialize service
    let result = init_service(&file_path, "Test Service".to_string()).unwrap();

    // Verify the result
    assert_eq!(result.service.name, "Test Service");
    assert_eq!(result.file_path, file_path);

    // Verify the file was created
    assert!(file_path.exists());

    // Parse the created file to verify its contents
    let file_content = std::fs::read_to_string(file_path).unwrap();
    let parsed_service: ServiceJson = serde_json::from_str(&file_content).unwrap();

    assert_eq!(parsed_service.name, "Test Service");

    // Test with autogenerated ID
    let auto_id_file_path = temp_dir.path().join("auto_id_test.json");

    // Initialize service with no ID (should generate one)
    let auto_id_result = init_service(&auto_id_file_path, "Auto ID Service".to_string()).unwrap();

    // Verify name
    assert_eq!(auto_id_result.service.name, "Auto ID Service");

    // Verify file was created
    assert!(auto_id_file_path.exists());

    // Parse file to verify contents
    let auto_id_content = std::fs::read_to_string(auto_id_file_path).unwrap();
    let auto_id_parsed: ServiceJson = serde_json::from_str(&auto_id_content).unwrap();

    assert_eq!(auto_id_parsed.name, "Auto ID Service");
}

#[tokio::test]
async fn test_workflow_component_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("component_operations_test.json");

    // Create a test digest - raw 64-character hex string (32 bytes)
    let test_digest = ComponentDigest::from_str(
        "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
    )
    .unwrap();

    // Initialize a service using the init_service method
    let init_result = init_service(&file_path, "Test Service".to_string()).unwrap();

    // Verify initialization result
    assert_eq!(init_result.service.name, "Test Service");
    assert_eq!(init_result.file_path, file_path);

    // Need to have a valid workflow before we can work on its component
    let workflow_id = WorkflowId::new("workflow-1").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Test adding first component using Digest source
    let add_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::SetSourceDigest {
            digest: test_digest.clone(),
        },
    )
    .await
    .unwrap();

    // Verify add result
    match &add_result {
        ComponentOperationResult::SourceDigest { digest, .. } => {
            assert_eq!(*digest, test_digest);
        }
        _ => panic!("Expected SourceDigest result"),
    }
    assert_eq!(add_result.file_path(), &file_path);

    // Verify the file was modified by adding the component
    let service_after_add: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_add
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .is_set());

    // Test adding second component with Digest source
    let workflow_id_2 = WorkflowId::new("workflow-2").unwrap();
    add_workflow(&file_path, Some(workflow_id_2.clone())).unwrap();

    let second_add_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id_2.clone(),
        ComponentCommand::SetSourceDigest {
            digest: test_digest.clone(),
        },
    )
    .await
    .unwrap();

    // Verify second add result
    match &second_add_result {
        ComponentOperationResult::SourceDigest { digest, .. } => {
            assert_eq!(*digest, test_digest);
        }
        _ => panic!("Expected SourceDigest result"),
    }

    // Test updating permissions - allow all HTTP hosts
    let permissions_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Permissions {
            http_hosts: Some(vec!["*".to_string()]),
            file_system: Some(true),
        },
    )
    .await
    .unwrap();

    // Verify permissions result
    match &permissions_result {
        ComponentOperationResult::Permissions { permissions, .. } => {
            assert!(permissions.file_system);
            assert!(matches!(
                permissions.allowed_http_hosts,
                AllowedHostPermission::All
            ));
        }
        _ => panic!("Expected Permissions result"),
    }

    // Verify the service was updated with new permissions
    let service_after_permissions: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let updated_component = service_after_permissions
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert!(updated_component.permissions.file_system);
    assert!(matches!(
        updated_component.permissions.allowed_http_hosts,
        AllowedHostPermission::All
    ));

    // Test updating to specific HTTP hosts
    let specific_hosts = vec!["example.com".to_string(), "api.example.com".to_string()];
    let specific_hosts_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id_2.clone(),
        ComponentCommand::Permissions {
            http_hosts: Some(specific_hosts.clone()),
            file_system: None,
        },
    )
    .await
    .unwrap();

    // Verify specific hosts result
    match &specific_hosts_result {
        ComponentOperationResult::Permissions { permissions, .. } => {
            if let AllowedHostPermission::Only(hosts) = &permissions.allowed_http_hosts {
                assert_eq!(hosts.len(), 2);
                assert!(hosts.contains(&"example.com".to_string()));
                assert!(hosts.contains(&"api.example.com".to_string()));
            } else {
                panic!("Expected AllowedHostPermission::Only");
            }
        }
        _ => panic!("Expected Permissions result"),
    }

    // Verify the service was updated with specific hosts
    let service_after_specific: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let specific_component = service_after_specific
        .workflows
        .get(&workflow_id_2)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    if let AllowedHostPermission::Only(hosts) = &specific_component.permissions.allowed_http_hosts {
        assert_eq!(hosts.len(), 2);
        assert!(hosts.contains(&"example.com".to_string()));
        assert!(hosts.contains(&"api.example.com".to_string()));
    } else {
        panic!("Expected AllowedHostPermission::Only");
    }

    // Test updating to no HTTP hosts
    let no_hosts_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Permissions {
            http_hosts: Some(vec![]),
            file_system: None,
        },
    )
    .await
    .unwrap();

    // Verify no hosts result
    match &no_hosts_result {
        ComponentOperationResult::Permissions { permissions, .. } => {
            assert!(matches!(
                permissions.allowed_http_hosts,
                AllowedHostPermission::None
            ));
        }
        _ => panic!("Expected Permissions result"),
    }

    // Verify the service was updated with no hosts permission
    let service_after_no_hosts: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let no_hosts_component = service_after_no_hosts
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    assert!(matches!(
        no_hosts_component.permissions.allowed_http_hosts,
        AllowedHostPermission::None
    ));

    // Test error handling for permissions update with non-existent component
    let non_existent_id = WorkflowId::new("does-not-exist").unwrap();
    let error_permissions = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        non_existent_id.clone(),
        ComponentCommand::Permissions {
            http_hosts: Some(vec!["*".to_string()]),
            file_system: None,
        },
    )
    .await;

    // Verify error for permissions update
    assert!(error_permissions.is_err());
    let permissions_error = error_permissions.unwrap_err().to_string();
    assert!(permissions_error.contains(&non_existent_id.to_string()));
    assert!(permissions_error.contains("not found"));

    // Test adding third component with Digest source
    // Need to have a valid workflow before we can work on its component
    let workflow_id_3 = WorkflowId::new("workflow-3").unwrap();
    add_workflow(&file_path, Some(workflow_id_3.clone())).unwrap();

    let third_add_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id_3.clone(),
        ComponentCommand::SetSourceDigest {
            digest: test_digest.clone(),
        },
    )
    .await
    .unwrap();

    // Verify third add result
    match &third_add_result {
        ComponentOperationResult::SourceDigest { digest, .. } => {
            assert_eq!(*digest, test_digest);
        }
        _ => panic!("Expected SourceDigest result"),
    }

    // Verify the third component was added
    let service_after_third_add: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_third_add
        .workflows
        .get(&workflow_id_3)
        .unwrap()
        .component
        .is_set());

    // Test setting a specific fuel limit
    let fuel_limit = 50000u64;
    let fuel_limit_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::FuelLimit {
            fuel: Some(fuel_limit),
        },
    )
    .await
    .unwrap();

    // Verify fuel limit result
    match &fuel_limit_result {
        ComponentOperationResult::FuelLimit {
            fuel_limit: result_fuel_limit,
            ..
        } => {
            assert_eq!(*result_fuel_limit, Some(fuel_limit));
        }
        _ => panic!("Expected FuelLimit result"),
    }
    assert_eq!(fuel_limit_result.file_path(), &file_path);

    // Verify the service was updated with the fuel limit
    let service_after_fuel_limit: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_fuel_limit = service_after_fuel_limit
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_fuel_limit.fuel_limit, Some(fuel_limit));

    // Test removing a fuel limit (setting to None)
    let no_fuel_limit_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::FuelLimit { fuel: None },
    )
    .await
    .unwrap();

    // Verify no fuel limit result
    match &no_fuel_limit_result {
        ComponentOperationResult::FuelLimit { fuel_limit, .. } => {
            assert_eq!(*fuel_limit, None);
        }
        _ => panic!("Expected FuelLimit result"),
    }
    assert_eq!(no_fuel_limit_result.file_path(), &file_path);

    // Verify the service was updated with no fuel limit
    let service_after_no_fuel: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_no_fuel = service_after_no_fuel
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_no_fuel.fuel_limit, None);

    // Test adding configuration values
    let config_values = vec![
        "api_key=123456".to_string(),
        "timeout=30".to_string(),
        "debug=true".to_string(),
    ];
    let config_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Config {
            values: Some(config_values.clone()),
            config_file: None,
        },
    )
    .await
    .unwrap();

    // Verify config result
    match &config_result {
        ComponentOperationResult::Config { config, .. } => {
            assert_eq!(config.len(), 3);
            assert!(config.iter().any(|(k, v)| k == "api_key" && v == "123456"));
            assert!(config.iter().any(|(k, v)| k == "timeout" && v == "30"));
            assert!(config.iter().any(|(k, v)| k == "debug" && v == "true"));
        }
        _ => panic!("Expected Config result"),
    }
    assert_eq!(config_result.file_path(), &file_path);

    // Verify the service was updated with the config
    let service_after_config: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_config = service_after_config
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_config.config.len(), 3);
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "api_key" && v == "123456"));
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "timeout" && v == "30"));
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "debug" && v == "true"));

    // Test clearing configuration (set to None)
    let clear_config_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Config {
            values: None,
            config_file: None,
        },
    )
    .await
    .unwrap();

    // Verify clear config result
    match &clear_config_result {
        ComponentOperationResult::Config { config, .. } => {
            assert_eq!(config.len(), 0);
        }
        _ => panic!("Expected Config result"),
    }
    assert_eq!(clear_config_result.file_path(), &file_path);

    // Verify the service was updated with empty config
    let service_after_clear_config: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_clear_config = service_after_clear_config
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_clear_config.config.len(), 0);

    // Test with invalid config format
    let invalid_config = vec!["invalid_format".to_string()];
    let invalid_config_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Config {
            values: Some(invalid_config),
            config_file: None,
        },
    )
    .await;

    // Verify it returns an error for invalid format
    assert!(invalid_config_result.is_err());
    let error_msg = invalid_config_result.unwrap_err().to_string();
    assert!(error_msg.contains("Invalid config format"));
    assert!(error_msg.contains("Expected 'key=value'"));

    // Test adding environment variables
    let env_keys = vec![
        "WAVS_ENV_API_KEY".to_string(),
        "WAVS_ENV_SECRET_TOKEN".to_string(),
        "WAVS_ENV_DATABASE_URL".to_string(),
    ];

    let env_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Env {
            values: Some(env_keys.clone()),
        },
    )
    .await
    .unwrap();

    // Verify env result
    match &env_result {
        ComponentOperationResult::EnvKeys { env_keys, .. } => {
            assert_eq!(env_keys.len(), 3);
            assert!(env_keys.contains("WAVS_ENV_API_KEY"));
            assert!(env_keys.contains("WAVS_ENV_SECRET_TOKEN"));
            assert!(env_keys.contains("WAVS_ENV_DATABASE_URL"));
        }
        _ => panic!("Expected EnvKeys result"),
    }

    // Verify the service was updated with env keys
    let service_after_env: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_env = service_after_env
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    assert_eq!(component_with_env.env_keys.len(), 3);
    assert!(component_with_env.env_keys.contains("WAVS_ENV_API_KEY"));
    assert!(component_with_env
        .env_keys
        .contains("WAVS_ENV_SECRET_TOKEN"));
    assert!(component_with_env
        .env_keys
        .contains("WAVS_ENV_DATABASE_URL"));

    // Test validation of env keys
    let invalid_env_keys = vec!["WAVS_ENV_VALID".to_string(), "INVALID_PREFIX".to_string()];

    let invalid_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Env {
            values: Some(invalid_env_keys),
        },
    )
    .await;

    // Verify it returns an error for invalid prefix
    assert!(invalid_result.is_err());
    let error_msg = invalid_result.unwrap_err().to_string();
    assert!(error_msg.contains("must start with 'WAVS_ENV'"));

    // Test clearing env keys
    let clear_env_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Env { values: None },
    )
    .await
    .unwrap();

    // Verify clear result
    match &clear_env_result {
        ComponentOperationResult::EnvKeys { env_keys, .. } => {
            assert_eq!(env_keys.len(), 0);
        }
        _ => panic!("Expected EnvKeys result"),
    }

    // Test setting a specific max execution time
    let max_exec_time = 120u64;
    let max_exec_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id_2.clone(),
        ComponentCommand::TimeLimit {
            seconds: Some(max_exec_time),
        },
    )
    .await
    .unwrap();

    // Verify max exec time result
    match &max_exec_result {
        ComponentOperationResult::TimeLimit {
            time_limit_seconds, ..
        } => {
            assert_eq!(*time_limit_seconds, Some(max_exec_time));
        }
        _ => panic!("Expected TimeLimit result"),
    }
    assert_eq!(max_exec_result.file_path(), &file_path);

    // Verify the service was updated with max exec time
    let service_after_max_exec: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_max_exec = service_after_max_exec
        .workflows
        .get(&workflow_id_2)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(
        component_with_max_exec.time_limit_seconds,
        Some(max_exec_time)
    );

    // Test removing max exec time (setting to None)
    let no_max_exec_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id_2.clone(),
        ComponentCommand::TimeLimit { seconds: None },
    )
    .await
    .unwrap();

    // Verify no max exec time result
    match &no_max_exec_result {
        ComponentOperationResult::TimeLimit {
            time_limit_seconds, ..
        } => {
            assert_eq!(*time_limit_seconds, None);
        }
        _ => panic!("Expected TimeLimit result"),
    }
    assert_eq!(no_max_exec_result.file_path(), &file_path);

    // Verify the service was updated with no max exec time
    let service_after_no_max_exec: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_no_max_exec = service_after_no_max_exec
        .workflows
        .get(&workflow_id_2)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_no_max_exec.time_limit_seconds, None);
}

#[test]
fn test_workflow_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("workflow_operations_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Test adding a workflow with specific ID
    let workflow_id = WorkflowId::new("workflow-123").unwrap();
    let add_result = add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Verify add result
    assert_eq!(add_result.workflow_id, workflow_id);
    assert_eq!(add_result.file_path, file_path);

    // Verify the file was modified by adding the workflow
    let service_after_add: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_add.workflows.contains_key(&workflow_id));
    assert_eq!(service_after_add.workflows.len(), 1);

    // Verify workflow properties - need to handle TriggerJson and SubmitJson wrappers
    let added_workflow = service_after_add.workflows.get(&workflow_id).unwrap();

    // Check trigger type with pattern matching for TriggerJson
    if let TriggerJson::Json(json) = &added_workflow.trigger {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Check component type
    assert!(added_workflow.component.is_unset());

    // Check submit type with pattern matching for SubmitJson
    if let SubmitJson::Json(json) = &added_workflow.submit {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Test adding a workflow with autogenerated ID
    let auto_id_result = add_workflow(&file_path, None).unwrap();
    let auto_workflow_id = auto_id_result.workflow_id;

    // Verify the auto-generated workflow was added
    let service_after_auto: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(service_after_auto.workflows.contains_key(&auto_workflow_id));
    assert_eq!(service_after_auto.workflows.len(), 2); // Two workflows now

    // Test deleting a workflow
    let delete_result = delete_workflow(&file_path, workflow_id.clone()).unwrap();

    // Verify delete result
    assert_eq!(delete_result.workflow_id, workflow_id);
    assert_eq!(delete_result.file_path, file_path);

    // Verify the file was modified by deleting the workflow
    let service_after_delete: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    assert!(!service_after_delete.workflows.contains_key(&workflow_id));
    assert_eq!(service_after_delete.workflows.len(), 1); // One workflow remaining

    // Test error handling for non-existent workflow
    let non_existent_workflow = WorkflowId::new("does-not-exist").unwrap();
    let workflow_error = delete_workflow(&file_path, non_existent_workflow.clone());

    // Verify it returns an error with appropriate message
    assert!(workflow_error.is_err());
    let workflow_error_msg = workflow_error.unwrap_err().to_string();
    assert!(workflow_error_msg.contains(&non_existent_workflow.to_string()));
    assert!(workflow_error_msg.contains("not found"));
}

#[tokio::test]
async fn test_update_status() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("update_status.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Update the status to Paused
    let result = update_status(&file_path, ServiceStatus::Paused).unwrap();

    // Assert the result reflects the new status and correct file path
    assert_eq!(result.status, ServiceStatus::Paused);
    assert_eq!(result.file_path, file_path);

    // Re-read the service file and assert the status was updated
    let contents = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&contents).unwrap();
    assert_eq!(service.status, ServiceStatus::Paused);
}

#[tokio::test]
async fn test_workflow_trigger_operations() {
    // Create a temporary directory and file
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("workflow_trigger_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Add a workflow
    let workflow_id = WorkflowId::new("workflow-123").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Initial workflow should have manual trigger (default when created)
    let service_initial: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let initial_workflow = service_initial.workflows.get(&workflow_id).unwrap();

    // Check the trigger type with proper handling of TriggerJson wrapper
    if let TriggerJson::Json(json) = &initial_workflow.trigger {
        assert!(matches!(json, Json::Unset));
    } else {
        panic!("Expected Json::Unset");
    }

    // Create a mock CosmosQueryClient for testing
    let cosmos_chain = ChainKey::from_str("cosmos:cosmoshub-4").unwrap();
    let chain_config = ChainConfig {
        chain_id: cosmos_chain.id.clone().into(),
        rpc_endpoint: Some("https://rpc.cosmos.network".to_string()),
        grpc_endpoint: Some("https://grpc.cosmos.network:443".to_string()),
        grpc_web_endpoint: Some("https://grpc-web.cosmos.network".to_string()),
        gas_price: 0.025,
        gas_denom: "uatom".to_string(),
        address_kind: layer_climb::prelude::AddrKind::Cosmos {
            prefix: "cosmos".to_string(),
        },
    };
    let query_client = CosmosQueryClient::new(chain_config, None)
        .await
        .expect("Failed to create Cosmos query client");

    // Test setting Cosmos trigger
    let cosmos_address = "cosmos1fl48vsnmsdzcv85q5d2q4z5ajdha8yu34mf0eh".to_string();
    let cosmos_event = "transfer".to_string();

    let cosmos_result = set_cosmos_trigger(
        query_client.clone(),
        &file_path,
        workflow_id.clone(),
        cosmos_address.clone(),
        cosmos_chain.clone(),
        cosmos_event.clone(),
    )
    .unwrap();

    // Verify cosmos trigger result
    assert_eq!(cosmos_result.workflow_id, workflow_id);
    if let Trigger::CosmosContractEvent {
        address,
        chain,
        event_type,
    } = &cosmos_result.trigger
    {
        assert_eq!(address.to_string(), cosmos_address);
        assert_eq!(chain, &cosmos_chain);
        assert_eq!(event_type, &cosmos_event);
    } else {
        panic!("Expected CosmosContractEvent trigger");
    }

    // Verify the service was updated with cosmos trigger
    let service_after_cosmos: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let cosmos_workflow = service_after_cosmos.workflows.get(&workflow_id).unwrap();

    // Handle TriggerJson wrapper
    if let TriggerJson::Trigger(trigger) = &cosmos_workflow.trigger {
        if let Trigger::CosmosContractEvent {
            address,
            chain,
            event_type,
        } = trigger
        {
            assert_eq!(address.to_string(), cosmos_address);
            assert_eq!(chain, &cosmos_chain);
            assert_eq!(event_type, &cosmos_event);
        } else {
            panic!("Expected CosmosContractEvent trigger in service");
        }
    } else {
        panic!("Expected TriggerJson::Trigger");
    }

    // Test for incorrect prefix - using Neutron (ntrn) prefix on Cosmos Hub
    let neutron_address = "ntrn1m8wnvy0jk8xf0hhn5uycrhjr3zpaqf4d0z9k8f".to_string();
    let wrong_prefix_result = set_cosmos_trigger(
        query_client.clone(),
        &file_path,
        workflow_id.clone(),
        neutron_address,
        cosmos_chain.clone(),
        cosmos_event.clone(),
    );

    // This should fail with a prefix validation error
    assert!(wrong_prefix_result.is_err());
    assert!(wrong_prefix_result
        .unwrap_err()
        .to_string()
        .contains("invalid bech32"),);

    // Test setting EVM trigger
    let evm_address = address!("0x00000000219ab540356cBB839Cbe05303d7705Fa");
    let evm_chain = ChainKey::from_str("evm:1").unwrap();
    let evm_event_hash =
        "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef".to_string();

    let evm_result = set_evm_trigger(
        &file_path,
        workflow_id.clone(),
        evm_address,
        evm_chain.clone(),
        evm_event_hash.clone(),
    )
    .unwrap();

    // Verify EVM trigger result
    assert_eq!(evm_result.workflow_id, workflow_id);
    if let Trigger::EvmContractEvent {
        address,
        chain,
        event_hash,
    } = &evm_result.trigger
    {
        assert_eq!(*address, evm_address);
        assert_eq!(chain, &evm_chain);
        // For event_hash we'll need to check the bytes match what we expect
        let expected_hash_bytes = hex::decode(evm_event_hash.trim_start_matches("0x")).unwrap();
        assert_eq!(event_hash.as_slice(), &expected_hash_bytes[..]);
    } else {
        panic!("Expected EvmContractEvent trigger");
    }

    // Verify the service was updated with EVM trigger
    let service_after: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let evm_workflow = service_after.workflows.get(&workflow_id).unwrap();

    // Handle TriggerJson wrapper
    if let TriggerJson::Trigger(trigger) = &evm_workflow.trigger {
        if let Trigger::EvmContractEvent {
            address,
            chain,
            event_hash,
        } = trigger
        {
            assert_eq!(*address, evm_address);
            assert_eq!(chain, &evm_chain);
            let expected_hash_bytes = hex::decode(evm_event_hash.trim_start_matches("0x")).unwrap();
            assert_eq!(event_hash.as_slice(), &expected_hash_bytes[..]);
        } else {
            panic!("Expected EvmContractEvent trigger in service");
        }
    } else {
        panic!("Expected TriggerJson::Trigger");
    }

    // Test error handling for non-existent workflow
    let non_existent_workflow = WorkflowId::new("does-not-exist").unwrap();
    let trigger_error = set_evm_trigger(
        &file_path,
        non_existent_workflow.clone(),
        evm_address,
        evm_chain.clone(),
        evm_event_hash.clone(),
    );

    // Verify it returns an error with appropriate message
    assert!(trigger_error.is_err());
    let trigger_error_msg = trigger_error.unwrap_err().to_string();
    assert!(trigger_error_msg.contains(&non_existent_workflow.to_string()));
    assert!(trigger_error_msg.contains("not found"));

    // Test error handling for invalid addresses
    let invalid_cosmos_address = "invalid-cosmos-address".to_string();
    let invalid_cosmos_result = set_cosmos_trigger(
        query_client, // Reuse the same query client
        &file_path,
        workflow_id.clone(),
        invalid_cosmos_address,
        cosmos_chain.clone(),
        cosmos_event.clone(),
    );
    assert!(invalid_cosmos_result.is_err());
    assert!(invalid_cosmos_result
        .unwrap_err()
        .to_string()
        .contains("invalid bech32"));

    // Test setting BlockInterval trigger
    let interval_chain = ChainKey::from_str("evm:polygon-mainnet").unwrap();
    let n_blocks = NonZeroU32::new(10).unwrap();

    let block_interval_result = set_block_interval_trigger(
        &file_path,
        workflow_id.clone(),
        interval_chain.clone(),
        n_blocks,
        Some(NonZeroU64::new(42).unwrap()),
        None,
    )
    .unwrap();

    assert_eq!(block_interval_result.workflow_id, workflow_id);
    if let Trigger::BlockInterval {
        chain,
        n_blocks: blocks,
        start_block,
        end_block,
    } = &block_interval_result.trigger
    {
        assert_eq!(chain, &interval_chain);
        assert_eq!(*blocks, n_blocks);
        assert_eq!(*start_block, Some(NonZeroU64::new(42).unwrap()));
        assert_eq!(*end_block, None);
    } else {
        panic!("Expected BlockInterval trigger");
    }

    // Test setting Cron trigger
    let cron_expr = "0 0 * * * *".to_string(); // every hour
    let start_time = Some(Timestamp::from_nanos(1_000_000_000_000_000_000));
    let end_time = Some(Timestamp::from_nanos(2_000_000_000_000_000_000));

    let cron_result = set_cron_trigger(
        &file_path,
        workflow_id.clone(),
        cron::Schedule::from_str(&cron_expr).unwrap(),
        start_time,
        end_time,
    )
    .unwrap();

    assert_eq!(cron_result.workflow_id, workflow_id);
    if let Trigger::Cron {
        schedule,
        start_time: s,
        end_time: e,
    } = &cron_result.trigger
    {
        assert_eq!(schedule, &cron_expr);
        assert_eq!(s, &start_time);
        assert_eq!(e, &end_time);
    } else {
        panic!("Expected Cron trigger");
    }
}

#[tokio::test]
async fn test_service_validation() {
    // Create a temporary directory for test files
    let temp_dir = tempdir().unwrap();

    // Create common test objects
    let workflow_id = WorkflowId::new("workflow-123").unwrap();
    let evm_chain = ChainKey::from_str("evm:1").unwrap();
    let evm_address = alloy_primitives::Address::parse_checksummed(
        "0x00000000219ab540356cBB839Cbe05303d7705Fa",
        None,
    )
    .unwrap();

    // Create component with digest
    let test_digest = ComponentDigest::from_str(
        "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
    )
    .unwrap();
    let component = Component::new(ComponentSource::Digest(test_digest.clone()));

    // Create a valid trigger and submit for the workflow
    let trigger = Trigger::EvmContractEvent {
        address: evm_address,
        chain: evm_chain.clone(),
        event_hash: wavs_types::ByteArray::new([1u8; 32]),
    };

    let submit = Submit::Aggregator {
        url: "https://api.example.com/aggregator".to_string(),
        component: Box::new(component.clone()),
        signature_kind: SignatureKind::evm_default(),
    };

    // Create service manager
    let manager = ServiceManagerJson::Manager(ServiceManager::Evm {
        chain: evm_chain.clone(),
        address: evm_address,
    });

    // Test valid service
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let valid_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("valid_service.json");
        let service_json = serde_json::to_string_pretty(&valid_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert_eq!(
            result.errors.len(),
            0,
            "Valid service should have no validation errors"
        );
    }

    // Test unset component
    {
        let mut workflows = BTreeMap::new();
        // Add original workflow
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        // Add invalid workflow with unset component
        let invalid_workflow_id = WorkflowId::new("invalid-workflow").unwrap();
        workflows.insert(
            invalid_workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::new_unset(),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let invalid_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("unset_component.json");
        let service_json = serde_json::to_string_pretty(&invalid_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Service with unset component should have errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains(&invalid_workflow_id.to_string())
                    && error.contains("has an unset component")),
            "Validation should catch missing component reference"
        );
    }

    // Test zero fuel limit
    {
        let mut workflows = BTreeMap::new();
        let mut zero_fuel_component = component.clone();
        zero_fuel_component.fuel_limit = Some(0);

        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(zero_fuel_component),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let zero_fuel_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("zero_fuel_service.json");
        let service_json = serde_json::to_string_pretty(&zero_fuel_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Zero fuel service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains(&workflow_id.to_string())
                    && error.contains("fuel limit of zero")),
            "Validation should catch zero fuel limit"
        );
    }

    // Test empty service name
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let empty_name_service = ServiceJson {
            name: "".to_string(), // Empty name
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("empty_name_service.json");
        let service_json = serde_json::to_string_pretty(&empty_name_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Empty name service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("Service name cannot be empty")),
            "Validation should catch empty service name"
        );
    }

    // Test invalid environment variable prefix
    {
        let mut workflows = BTreeMap::new();
        let mut env_component = component.clone();
        env_component.env_keys = ["INVALID_PREFIX_KEY".to_string()].into_iter().collect();

        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(env_component),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let invalid_env_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("invalid_env_prefix.json");
        let service_json = serde_json::to_string_pretty(&invalid_env_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Invalid env prefix service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("doesn't start with 'WAVS_ENV'")),
            "Validation should catch invalid environment variable prefix"
        );
    }

    // Test unset trigger
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Json(Json::Unset),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let unset_trigger_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("unset_trigger.json");
        let service_json = serde_json::to_string_pretty(&unset_trigger_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Unset trigger service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("has an unset trigger")),
            "Validation should catch unset trigger"
        );
    }

    // Test unset submit
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Json(Json::Unset),
            },
        );

        let unset_submit_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("unset_submit.json");
        let service_json = serde_json::to_string_pretty(&unset_submit_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Unset submit service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("has an unset submit")),
            "Validation should catch unset submit"
        );
    }

    // Test invalid URL in Aggregator submit
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(Submit::Aggregator {
                    url: "not-a-valid-url".to_string(),
                    component: Box::new(component.clone()),
                    signature_kind: SignatureKind::evm_default(),
                }),
            },
        );

        let invalid_url_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: manager.clone(),
        };

        let file_path = temp_dir.path().join("invalid_url.json");
        let service_json = serde_json::to_string_pretty(&invalid_url_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Invalid URL service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("invalid URL")),
            "Validation should catch invalid URL in Aggregator submit"
        );
    }

    // Test unset service manager
    {
        let mut workflows = BTreeMap::new();
        workflows.insert(
            workflow_id.clone(),
            WorkflowJson {
                trigger: TriggerJson::Trigger(trigger.clone()),
                component: ComponentJson::Component(component.clone()),
                submit: SubmitJson::Submit(submit.clone()),
            },
        );

        let unset_manager_service = ServiceJson {
            name: "Test Service".to_string(),
            workflows,
            status: ServiceStatus::Active,
            manager: ServiceManagerJson::Json(Json::Unset),
        };

        let file_path = temp_dir.path().join("unset_manager.json");
        let service_json = serde_json::to_string_pretty(&unset_manager_service).unwrap();
        std::fs::write(&file_path, service_json).unwrap();

        let result = validate_service(&file_path, None).await.unwrap();
        assert!(
            !result.errors.is_empty(),
            "Unset manager service should have validation errors"
        );
        assert!(
            result
                .errors
                .iter()
                .any(|error| error.contains("unset service manager")),
            "Validation should catch unset service manager"
        );
    }
}

#[tokio::test]
async fn test_set_component_source_registry() {
    init_tracing_tests();
    // Create a temporary directory for the test
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("component_registry_test.json");

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Add a workflow
    let workflow_id = WorkflowId::new("workflow-123").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Test setting a component source to a registry
    let package = PackageRef::try_from("wavs-tests:square".to_string()).unwrap();

    // Use wa.dev as the registry domain (WAVS default)
    let registry_domain = "wa.dev".to_string();

    // Call the unified function to set the component source
    let result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::SetSourceRegistry {
            domain: None, // Use default domain
            package: package.clone(),
            version: None, // Use latest version
        },
    )
    .await;

    // Verify the operation was successful
    assert!(
        result.is_ok(),
        "Failed to set component source: {:?}",
        result.err()
    );

    let result = result.unwrap();

    // Basic validation of the result
    match &result {
        ComponentOperationResult::SourceRegistry {
            domain,
            package: result_package,
            ..
        } => {
            assert_eq!(*domain, registry_domain);
            assert_eq!(*result_package, package);
        }
        _ => panic!("Expected SourceRegistry result"),
    }
    match &result {
        ComponentOperationResult::SourceRegistry { digest, .. } => {
            assert!(!digest.to_string().is_empty(), "Digest should not be empty");
        }
        _ => panic!("Expected SourceRegistry result"),
    }

    // Verify the service was updated with the registry source
    let service_json = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&service_json).unwrap();

    let workflow = service.workflows.get(&workflow_id).unwrap();

    if let ComponentJson::Component(component) = &workflow.component {
        if let ComponentSource::Registry { registry } = &component.source {
            assert_eq!(registry.package, package);
            assert!(
                !registry.digest.to_string().is_empty(),
                "Digest in registry should not be empty"
            );
            match &result {
                ComponentOperationResult::SourceRegistry { digest, .. } => {
                    assert_eq!(
                        registry.digest, *digest,
                        "Digest in service file should match result digest"
                    );
                }
                _ => panic!("Expected SourceRegistry result"),
            }
            // We used defaults here
            assert!(registry.version.is_none());
            assert!(registry.domain.is_none());
        } else {
            panic!("Expected Registry component source");
        }
    } else {
        panic!("Expected Component");
    }
}

#[test]
fn test_set_aggregator_submit() {
    init_tracing_tests();
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("test_service.json");

    // Initialize service and add workflow
    init_service(&file_path, "Test Service".to_string()).unwrap();
    let workflow_result = add_workflow(&file_path, None).unwrap();
    let workflow_id = workflow_result.workflow_id;

    // Set aggregator submit
    let test_url = "https://example.com/aggregator";
    let result =
        set_aggregator_submit(&file_path, workflow_id.clone(), test_url.to_string()).unwrap();

    // Verify result
    assert_eq!(result.workflow_id, workflow_id);
    assert_eq!(result.url, test_url);

    // Verify the service file was updated
    let service_json = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&service_json).unwrap();
    let workflow = service.workflows.get(&workflow_id).unwrap();

    // Should create AggregatorJson with unset component
    match &workflow.submit {
        SubmitJson::AggregatorJson(AggregatorJson::Aggregator {
            url,
            component,
            signature_kind,
        }) => {
            assert_eq!(url, test_url);
            assert!(component.is_unset());
            assert_eq!(*signature_kind, SignatureKind::evm_default());
        }
        _ => panic!("Expected AggregatorJson variant"),
    }
}

#[test]
fn test_set_none_submit() {
    init_tracing_tests();
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("test_service.json");

    // Initialize service and add workflow
    init_service(&file_path, "Test Service".to_string()).unwrap();
    let workflow_result = add_workflow(&file_path, None).unwrap();
    let workflow_id = workflow_result.workflow_id;

    // Set none submit
    let result = set_none_submit(&file_path, workflow_id.clone()).unwrap();

    // Verify result
    assert_eq!(result.workflow_id, workflow_id);

    // Verify the service file was updated
    let service_json = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&service_json).unwrap();
    let workflow = service.workflows.get(&workflow_id).unwrap();

    // Should be Submit::None
    match &workflow.submit {
        SubmitJson::Submit(Submit::None) => {
            // Expected
        }
        _ => panic!("Expected Submit::None variant"),
    }
}

#[tokio::test]
async fn test_modify_aggregator_component() {
    init_tracing_tests();
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("test_service.json");

    // Initialize service and add workflow
    init_service(&file_path, "Test Service".to_string()).unwrap();
    let workflow_result = add_workflow(&file_path, None).unwrap();
    let workflow_id = workflow_result.workflow_id;

    // First set aggregator submit
    let test_url = "https://example.com/aggregator";
    set_aggregator_submit(&file_path, workflow_id.clone(), test_url.to_string()).unwrap();

    // Create test digest
    let test_digest = ComponentDigest::hash(b"test_component");

    // Test setting source digest on AggregatorJson
    let set_digest_cmd = ComponentCommand::SetSourceDigest {
        digest: test_digest.clone(),
    };
    let result = modify_aggregator_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        set_digest_cmd,
    )
    .await
    .unwrap();

    // Verify result
    assert_eq!(result.file_path(), &file_path);

    // Verify the component was created and set
    let service_json = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&service_json).unwrap();
    let workflow = service.workflows.get(&workflow_id).unwrap();

    match &workflow.submit {
        SubmitJson::AggregatorJson(AggregatorJson::Aggregator {
            url,
            component,
            signature_kind: _,
        }) => {
            assert_eq!(url, test_url);
            assert!(component.is_set());
            if let ComponentJson::Component(comp) = component {
                match &comp.source {
                    ComponentSource::Digest(digest) => {
                        assert_eq!(*digest, test_digest);
                    }
                    _ => panic!("Expected Digest source"),
                }
            }
        }
        SubmitJson::Submit(Submit::Aggregator {
            url,
            component,
            signature_kind: _,
        }) => {
            // This might be matched first due to enum ordering
            assert_eq!(*url, test_url);
            match &component.source {
                ComponentSource::Digest(digest) => {
                    assert_eq!(*digest, test_digest);
                }
                _ => panic!("Expected Digest source"),
            }
        }
        _ => panic!("Expected AggregatorJson or Submit::Aggregator variant"),
    }

    // Test modifying permissions on existing component
    let permissions_cmd = ComponentCommand::Permissions {
        http_hosts: Some(vec!["*".to_string()]),
        file_system: None,
    };
    modify_aggregator_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        permissions_cmd,
    )
    .await
    .unwrap();

    // Verify permissions were updated
    let service_json = std::fs::read_to_string(&file_path).unwrap();
    let service: ServiceJson = serde_json::from_str(&service_json).unwrap();
    let workflow = service.workflows.get(&workflow_id).unwrap();

    match &workflow.submit {
        SubmitJson::AggregatorJson(AggregatorJson::Aggregator { component, .. }) => {
            if let ComponentJson::Component(comp) = component {
                assert_eq!(
                    comp.permissions.allowed_http_hosts,
                    AllowedHostPermission::All
                );
            }
        }
        SubmitJson::Submit(Submit::Aggregator { component, .. }) => {
            // This might be matched first due to enum ordering
            assert_eq!(
                component.permissions.allowed_http_hosts,
                AllowedHostPermission::All
            );
        }
        _ => panic!("Expected AggregatorJson or Submit::Aggregator variant"),
    }
}

#[test]
fn test_aggregator_validation() {
    init_tracing_tests();

    // Test case 1: Valid aggregator with proper fuel limit
    let mut service = ServiceJson {
        name: "Test Service".to_string(),
        workflows: std::collections::BTreeMap::new(),
        status: ServiceStatus::Active,
        manager: ServiceManagerJson::Json(Json::Unset),
    };

    let workflow_id = WorkflowId::default();
    let test_digest = ComponentDigest::hash(b"test");
    let component = Component::new(ComponentSource::Digest(test_digest));

    let workflow = WorkflowJson {
        trigger: TriggerJson::Json(Json::Unset),
        component: ComponentJson::Component(Component::new(ComponentSource::Digest(
            ComponentDigest::hash(b"workflow_component"),
        ))),
        submit: SubmitJson::Submit(Submit::Aggregator {
            url: "https://valid-url.com".to_string(),
            component: Box::new(component.clone()),
            signature_kind: SignatureKind::evm_default(),
        }),
    };

    service.workflows.insert(workflow_id.clone(), workflow);

    let errors = service.validate();
    let submit_errors: Vec<_> = errors.iter().filter(|e| e.contains("aggregator")).collect();
    assert_eq!(
        submit_errors.len(),
        0,
        "Should have no aggregator validation errors"
    );

    // Test case 2: Invalid fuel limit (zero)
    let mut invalid_component = component.clone();
    invalid_component.fuel_limit = Some(0);

    let invalid_workflow = WorkflowJson {
        trigger: TriggerJson::Json(Json::Unset),
        component: ComponentJson::Component(Component::new(ComponentSource::Digest(
            ComponentDigest::hash(b"workflow_component"),
        ))),
        submit: SubmitJson::Submit(Submit::Aggregator {
            url: "https://valid-url.com".to_string(),
            component: Box::new(invalid_component),
            signature_kind: SignatureKind::evm_default(),
        }),
    };

    service
        .workflows
        .insert(workflow_id.clone(), invalid_workflow);

    let errors = service.validate();
    let fuel_errors: Vec<_> = errors
        .iter()
        .filter(|e| e.contains("fuel limit of zero"))
        .collect();
    assert_eq!(
        fuel_errors.len(),
        1,
        "Should have fuel limit validation error"
    );

    // Test case 3: Invalid env key prefix
    let mut invalid_env_component = component.clone();
    invalid_env_component
        .env_keys
        .insert("INVALID_PREFIX_KEY".to_string());

    let invalid_env_workflow = WorkflowJson {
        trigger: TriggerJson::Json(Json::Unset),
        component: ComponentJson::Component(Component::new(ComponentSource::Digest(
            ComponentDigest::hash(b"workflow_component"),
        ))),
        submit: SubmitJson::Submit(Submit::Aggregator {
            url: "https://valid-url.com".to_string(),
            component: Box::new(invalid_env_component),
            signature_kind: SignatureKind::evm_default(),
        }),
    };

    service.workflows.insert(workflow_id, invalid_env_workflow);

    let errors = service.validate();
    let env_errors: Vec<_> = errors
        .iter()
        .filter(|e| e.contains("doesn't start with"))
        .collect();
    assert_eq!(env_errors.len(), 1, "Should have env key validation error");
}

#[tokio::test]
async fn test_config_file_functionality() {
    // Test comprehensive config file functionality including parsing and end-to-end integration
    let temp_dir = tempdir().unwrap();
    let file_path = temp_dir.path().join("config_test_service.json");
    let config_file = temp_dir.path().join("component_config.json");

    // Test valid JSON config file with comprehensive data types
    let comprehensive_config = r#"{
        "database_host": "localhost",
        "database_port": "5432",
        "api_timeout": "30",
        "debug_enabled": "true",
        "max_connections": "100",
        "retry_count": "3",
        "allowed_ips": ["127.0.0.1", "192.168.1.100"],
        "database_config": {"ssl": true, "pool_size": 10},
        "feature_flags": {"new_ui": true, "beta_access": false}
    }"#;

    std::fs::write(&config_file, comprehensive_config).unwrap();

    let result = parse_config_from_file(&config_file).unwrap();

    assert_eq!(result.len(), 9);
    assert_eq!(result.get("database_host"), Some(&"localhost".to_string()));
    assert_eq!(result.get("database_port"), Some(&"5432".to_string()));
    assert_eq!(result.get("api_timeout"), Some(&"30".to_string()));
    assert_eq!(result.get("debug_enabled"), Some(&"true".to_string()));
    assert_eq!(result.get("max_connections"), Some(&"100".to_string()));
    assert_eq!(result.get("retry_count"), Some(&"3".to_string()));

    // Verify complex types are serialized as JSON strings
    if let Some(ips_str) = result.get("allowed_ips") {
        let ips: Vec<String> = serde_json::from_str(ips_str).unwrap();
        assert_eq!(ips.len(), 2);
        assert!(ips.contains(&"127.0.0.1".to_string()));
        assert!(ips.contains(&"192.168.1.100".to_string()));
    }

    if let Some(db_config_str) = result.get("database_config") {
        let db_config: serde_json::Value = serde_json::from_str(db_config_str).unwrap();
        if let serde_json::Value::Object(obj) = db_config {
            assert_eq!(obj.get("ssl").and_then(|v| v.as_bool()), Some(true));
            assert_eq!(obj.get("pool_size").and_then(|v| v.as_u64()), Some(10));
        }
    }

    // Test error conditions
    let non_existent_file = temp_dir.path().join("non_existent.json");
    let result = parse_config_from_file(&non_existent_file);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .to_string()
        .contains("Failed to read config file"));

    let invalid_json_file = temp_dir.path().join("invalid.json");
    std::fs::write(&invalid_json_file, "{ invalid json }").unwrap();

    let result = parse_config_from_file(&invalid_json_file);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .to_string()
        .contains("Failed to parse JSON"));

    let array_file = temp_dir.path().join("array.json");
    std::fs::write(&array_file, "[]").unwrap();

    let result = parse_config_from_file(&array_file);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .to_string()
        .contains("must contain a JSON object"));

    // Test complex types (should be serialized as JSON strings)
    let nested_file = temp_dir.path().join("nested.json");
    std::fs::write(
        &nested_file,
        r#"{"database": {"host": "localhost"}, "port": "5432"}"#,
    )
    .unwrap();

    let result = parse_config_from_file(&nested_file).unwrap();
    assert_eq!(result.len(), 2);
    assert_eq!(
        result.get("database"),
        Some(&r#"{"host":"localhost"}"#.to_string())
    );
    assert_eq!(result.get("port"), Some(&"5432".to_string()));

    let array_value_file = temp_dir.path().join("array_value.json");
    std::fs::write(
        &array_value_file,
        r#"{"hosts": ["localhost", "127.0.0.1"], "count": 2}"#,
    )
    .unwrap();

    let result = parse_config_from_file(&array_value_file).unwrap();
    assert_eq!(result.len(), 2);
    assert_eq!(
        result.get("hosts"),
        Some(&r#"["localhost","127.0.0.1"]"#.to_string())
    );
    assert_eq!(result.get("count"), Some(&"2".to_string()));

    let null_file = temp_dir.path().join("null.json");
    std::fs::write(
        &null_file,
        r#"{"database_host": "localhost", "optional_value": null}"#,
    )
    .unwrap();

    let result = parse_config_from_file(&null_file);
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("null value"));

    // Initialize a service
    init_service(&file_path, "Test Service".to_string()).unwrap();

    // Add a workflow
    let workflow_id = WorkflowId::new("workflow-config-test").unwrap();
    add_workflow(&file_path, Some(workflow_id.clone())).unwrap();

    // Set component source first
    let test_digest = ComponentDigest::from_str(
        "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
    )
    .unwrap();
    update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::SetSourceDigest {
            digest: test_digest.clone(),
        },
    )
    .await
    .unwrap();

    // Config file already contains comprehensive config from unit test section

    // Test setting config from file
    let config_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Config {
            values: None,
            config_file: Some(config_file.clone()),
        },
    )
    .await
    .unwrap();

    // Verify config result with all data types
    match &config_result {
        ComponentOperationResult::Config { config, .. } => {
            assert_eq!(config.len(), 9);

            // Simple values
            assert_eq!(config.get("database_host"), Some(&"localhost".to_string()));
            assert_eq!(config.get("database_port"), Some(&"5432".to_string()));
            assert_eq!(config.get("api_timeout"), Some(&"30".to_string()));
            assert_eq!(config.get("debug_enabled"), Some(&"true".to_string()));
            assert_eq!(config.get("max_connections"), Some(&"100".to_string()));
            assert_eq!(config.get("retry_count"), Some(&"3".to_string()));

            // Array serialization
            if let Some(ips_str) = config.get("allowed_ips") {
                let ips: Vec<String> = serde_json::from_str(ips_str).unwrap();
                assert_eq!(ips.len(), 2);
                assert!(ips.contains(&"127.0.0.1".to_string()));
                assert!(ips.contains(&"192.168.1.100".to_string()));
            } else {
                panic!("allowed_ips not found in config");
            }

            // Object serialization - database_config
            if let Some(db_config_str) = config.get("database_config") {
                let db_config: serde_json::Value = serde_json::from_str(db_config_str).unwrap();
                if let serde_json::Value::Object(obj) = db_config {
                    assert_eq!(obj.get("ssl").and_then(|v| v.as_bool()), Some(true));
                    assert_eq!(obj.get("pool_size").and_then(|v| v.as_u64()), Some(10));
                } else {
                    panic!("database_config should be an object");
                }
            } else {
                panic!("database_config not found in config");
            }

            // Object serialization - feature_flags
            if let Some(feature_flags_str) = config.get("feature_flags") {
                let feature_flags: serde_json::Value =
                    serde_json::from_str(feature_flags_str).unwrap();
                if let serde_json::Value::Object(obj) = feature_flags {
                    assert_eq!(obj.get("new_ui").and_then(|v| v.as_bool()), Some(true));
                    assert_eq!(
                        obj.get("beta_access").and_then(|v| v.as_bool()),
                        Some(false)
                    );
                } else {
                    panic!("feature_flags should be an object");
                }
            } else {
                panic!("feature_flags not found in config");
            }
        }
        _ => panic!("Expected Config result"),
    }

    // Verify the service was updated with the config
    let service_after_config: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_config = service_after_config
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();

    assert_eq!(component_with_config.config.len(), 9);
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "database_host" && v == "localhost"));
    assert!(component_with_config
        .config
        .iter()
        .any(|(k, v)| k == "database_port" && v == "5432"));

    // Test clearing config
    let clear_config_result = update_workflow_component(
        DEFAULT_IPFS_GATEWAY,
        &file_path,
        workflow_id.clone(),
        ComponentCommand::Config {
            values: None,
            config_file: None,
        },
    )
    .await
    .unwrap();

    match &clear_config_result {
        ComponentOperationResult::Config { config, .. } => {
            assert_eq!(config.len(), 0);
        }
        _ => panic!("Expected Config result"),
    }

    let service_after_clear: ServiceJson =
        serde_json::from_str(&std::fs::read_to_string(&file_path).unwrap()).unwrap();
    let component_with_clear_config = service_after_clear
        .workflows
        .get(&workflow_id)
        .unwrap()
        .component
        .as_component()
        .unwrap();
    assert_eq!(component_with_clear_config.config.len(), 0);
}
